{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concrete data set\n",
    "\n",
    "We have 1030 observations on 9 variables. We try to estimate the Complete compressive strength(CRS) using:\n",
    "\n",
    "| Variable   | Description |\n",
    "| ---------- | ---------------- |\n",
    "| Cement in kg  | Cement in a m3 mixture | \n",
    "| Blast Furnace Slag in kg  | Blast Furnace Slag  in a m3 mixture | \n",
    "| Fly Ash in kg | Fly Ash in a m3 mixture | \n",
    "| Water in kg |  in a m3 mixture | \n",
    "| Superplasticizer in kg | Water in a m3 mixture | \n",
    "| Coarse Aggregate in kg  |Coarse Aggregate in a m3 mixture | \n",
    "| Fine Aggregate in kg  | Fine Aggregatein a m3 mixture | \n",
    "| Age in  Day  | Days (1-365) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas                       as     pd\n",
    "import numpy                        as     np\n",
    "import scipy.stats                  as     stats\n",
    "\n",
    "import seaborn                      as     sns\n",
    "import matplotlib.pyplot            as     plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "from   statsmodels.compat           import lzip\n",
    "\n",
    "from   sklearn                      import model_selection\n",
    "\n",
    "from sklearn.linear_model           import  LinearRegression\n",
    "from sklearn.linear_model           import  Lasso\n",
    "from sklearn.linear_model           import  Ridge\n",
    "from sklearn.linear_model           import  ElasticNet\n",
    "\n",
    "from   sklearn.tree                 import DecisionTreeRegressor\n",
    "from   sklearn.ensemble             import RandomForestRegressor\n",
    "from   sklearn.neural_network       import MLPRegressor\n",
    "from   sklearn                      import ensemble\n",
    "from   sklearn.ensemble             import GradientBoostingRegressor\n",
    "\n",
    "from   sklearn.neighbors            import KNeighborsRegressor\n",
    "from   sklearn.svm                  import SVR\n",
    "\n",
    "from   sklearn.model_selection      import GridSearchCV\n",
    "from   sklearn.model_selection      import cross_val_score, cross_val_predict\n",
    "\n",
    "\n",
    "from   sklearn.metrics              import mean_squared_error, mean_absolute_error\n",
    "from   statsmodels.compat           import lzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  report_rmse_mape(lm, y, X, title):\n",
    "    \n",
    "    '''\n",
    "        Reports rmse and mape for the given model, pair of dataset (y and X) and title\n",
    "    ''' \n",
    "    rmse_     = (np.sqrt(mean_squared_error(y_true = y, y_pred = lm.predict(X))))\n",
    "    mape_    = mean_absolute_percentage_error(y,       y_pred = lm.predict(X))\n",
    "    print(\"\\n\")\n",
    "    print(title)\n",
    "    print(\"--------------------------------------\")\n",
    "    print('RMSE is {}'.format(rmse_ ))\n",
    "    print('MAPE is {}'.format(mape_))\n",
    "\n",
    "#### End\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 9)\n",
      "(206, 9)\n",
      "                        0       1       2       3        4\n",
      "Cement             275.10  516.00  393.00  183.90   246.80\n",
      "Blast                0.00    0.00    0.00  122.60     0.00\n",
      "Fly Ash            121.40    0.00    0.00    0.00   125.10\n",
      "Water              159.50  162.00  192.00  203.50   143.30\n",
      "Superplasticizer     9.90    8.20    0.00    0.00    12.00\n",
      "CA                1053.60  801.00  940.00  959.20  1086.80\n",
      "FA                 777.50  802.00  758.00  800.00   800.90\n",
      "Age                 56.00   28.00   90.00   28.00     3.00\n",
      "CMS                 56.85   41.37   48.79   24.05    23.52\n",
      "                      0      1       2        3       4\n",
      "Cement            318.8  362.6  322.00   212.00  446.00\n",
      "Blast             212.5  189.0    0.00     0.00   24.00\n",
      "Fly Ash             0.0    0.0    0.00   124.80   79.00\n",
      "Water             155.7  164.9  203.00   159.00  162.00\n",
      "Superplasticizer   14.3   11.6    0.00     7.80   11.60\n",
      "CA                852.1  944.7  974.00  1085.40  967.00\n",
      "FA                880.4  755.8  800.00   799.50  712.00\n",
      "Age                91.0   28.0   28.00     3.00    7.00\n",
      "CMS                68.1   71.3   25.18    19.52   38.02\n"
     ]
    }
   ],
   "source": [
    "train_df       =   pd.read_csv('train.csv', usecols =  ['Cement', 'Blast', 'Fly Ash', 'Water', 'Superplasticizer',\\\n",
    "       'CA', 'FA', 'Age', 'CMS'])\n",
    "test_df        =   pd.read_csv('test.csv')\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(train_df.head().T)   \n",
    "print(test_df.head().T)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train  = train_df[['Cement', 'Blast', 'Fly Ash', 'Water', 'Superplasticizer','CA', 'FA', 'Age']]\n",
    "X_test   = test_df[['Cement', 'Blast', 'Fly Ash', 'Water', 'Superplasticizer','CA', 'FA', 'Age']]\n",
    "y_train  = train_df['CMS'] \n",
    "y_test   = test_df['CMS']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x_train shape', (823, 8), pandas.core.frame.DataFrame),\n",
       " ('x_test shape', (206, 8), pandas.core.frame.DataFrame),\n",
       " ('y_train shape', (823,), pandas.core.series.Series),\n",
       " ('y_test shape', (206,), pandas.core.series.Series)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names      = ['x_train shape', 'x_test shape', 'y_train shape', 'y_test shape']\n",
    "shapes        = (X_train.shape, X_test.shape,  y_train.shape, y_test.shape)\n",
    "types         = (type(X_train), type(X_test), type(y_train),type(y_test))\n",
    "lzip(df_names,shapes, types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy\n",
    "\n",
    "Prediction error or residuals is the difference between the predicted target variable values and the actual target variable vaues.\n",
    "\n",
    "Most popular measure to evaluate the model performance is Root Mean Square Error (RMSE) which is the arithmatic mean of the sum of the residuals.\n",
    "The model with low RMSE is the best model among many other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed                  =   12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_ols              =   LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ols.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\OLS Multiple Linear Regression Models\n",
      "\n",
      "R Square value for Ridge Regression complete data 61.23\n"
     ]
    }
   ],
   "source": [
    "print('\\OLS Multiple Linear Regression Models\\n')\n",
    "print(\"R Square value for Ridge Regression complete data %4.2f\" % np.round(lm_ols.score(X_train, y_train) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model performance for training set - \n",
      "OLS regression\n",
      "--------------------------------------\n",
      "RMSE is 10.284254442304984\n",
      "MAPE is 30.736849660088144\n"
     ]
    }
   ],
   "source": [
    "report_rmse_mape(lm_ols, y_train, X_train, 'The model performance for training set - \\nOLS regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model performance for test set - \n",
      "OLS regression\n",
      "--------------------------------------\n",
      "RMSE is 10.6308239107729\n",
      "MAPE is 32.80051602830256\n"
     ]
    }
   ],
   "source": [
    "report_rmse_mape(lm_ols, y_test, X_test, 'The model performance for test set - \\nOLS regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_ridge              =   Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Square value for Ridge Regression complete data 61.23\n"
     ]
    }
   ],
   "source": [
    "print(\"R Square value for Ridge Regression complete data %4.2f\" \\\n",
    "      % np.round(lm_ridge.score(X_train, y_train) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Ridge regression\n",
      "--------------------------------------\n",
      "RMSE is 10.630824528151651\n",
      "MAPE is 32.800547581387825\n"
     ]
    }
   ],
   "source": [
    "report_rmse_mape(lm_ridge, y, X, 'The model performance for training set - \\nRidge regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Ridge regression\n",
      "--------------------------------------\n",
      "RMSE is 10.630824528151651\n",
      "MAPE is 32.800547581387825\n"
     ]
    }
   ],
   "source": [
    "report_rmse_mape(lm_ridge, y, X, 'The model performance for testing set - \\nRidge regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_lasso              =   Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Square value for Lasso Regression complete data 61.20\n"
     ]
    }
   ],
   "source": [
    "print(\"R Square value for Lasso Regression complete data %4.2f\" \\\n",
    "      %np.round(lm_lasso.score(X_train, y_train) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Lasso regression\n",
      "--------------------------------------\n",
      "RMSE is 10.63250210808717\n",
      "MAPE is 32.901672169697\n"
     ]
    }
   ],
   "source": [
    "report_rmse_mape(lm_lasso, y, X, \\\n",
    "                 'The model performance for training set - \\nLasso regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Lasso regression\n",
      "--------------------------------------\n",
      "RMSE is 10.63250210808717\n",
      "MAPE is 32.901672169697\n"
     ]
    }
   ],
   "source": [
    "report_rmse_mape(lm_lasso, y, X, \\\n",
    "                 'The model performance for testing set - \\nLasso regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=12345,\n",
       "       shuffle=True, solver='adam', tol=0.001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lm_elastic            =   ElasticNet()\n",
    "lm_elastic            =   ElasticNet()\n",
    "\n",
    "### Non linear models\n",
    "\n",
    "kfold                 =   model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "lm_CART               =   DecisionTreeRegressor()\n",
    "lm_RF                 =   RandomForestRegressor(random_state = seed)\n",
    "lm_ANN                =   MLPRegressor(alpha=0.000001, activation = 'tanh', random_state = seed, tol = 0.001)\n",
    "lm_GB                 =   ensemble.GradientBoostingRegressor()\n",
    "lm_SVR                =   SVR(kernel='linear', C=1.0, epsilon=0.2, )\n",
    "lm_KNN                =   KNeighborsRegressor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lm_elastic.fit(X_train, y_train) \n",
    "lm_CART.fit(X_train, y_train) \n",
    "lm_RF.fit(X_train, y_train)\n",
    "lm_GB.fit(X_train, y_train)\n",
    "lm_SVR.fit(X_train, y_train)  \n",
    "lm_KNN.fit(X_train, y_train)  \n",
    "lm_ANN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other Linear Models\n",
      "\n",
      "R Square value for Ridge Regression complete data 61.23\n",
      "R Square value for Lasso Regression complete data 61.20\n",
      "R Square value for Elastic Net Regression complete data 61.22\n"
     ]
    }
   ],
   "source": [
    "print('\\nOther Linear Models\\n')\n",
    "\n",
    "\n",
    "\n",
    "print(\"R Square value for Elastic Net Regression complete data %4.2f\" % np.round(lm_elastic.score(X_train,y_train) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non linear Models\n",
      "\n",
      "R Square value for CART Regression complete data 99.88\n",
      "R Square value for Random Forest Regression complete data 98.21\n",
      "R Square value for Artificial Neural Network Regression complete data 3.54\n",
      "R Square value for Gradient Boosting Regression complete data 95.12\n",
      "R Square value for SVR Regression complete data 59.20\n",
      "R Square value for KNN Regression complete data 81.20\n"
     ]
    }
   ],
   "source": [
    "print('\\nNon linear Models\\n')\n",
    "print(\"R Square value for CART Regression complete data %4.2f\" % np.round(lm_CART.score(X_train,y_train) * 100, 2))\n",
    "print(\"R Square value for Random Forest Regression complete data %4.2f\" % np.round(lm_RF.score(X_train,y_train) * 100, 2))\n",
    "print(\"R Square value for Artificial Neural Network Regression complete data %4.2f\" % np.round(lm_ANN.score(X_train,y_train) * 100, 2))\n",
    "\n",
    "print(\"R Square value for Gradient Boosting Regression complete data %4.2f\" % np.round(lm_GB.score(X_train,y_train) * 100, 2))\n",
    "print(\"R Square value for SVR Regression complete data %4.2f\" % np.round(lm_SVR.score(X_train,y_train) * 100, 2))\n",
    "print(\"R Square value for KNN Regression complete data %4.2f\" % np.round(lm_KNN.score(X_train,y_train) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### For testing dataset\n",
    "seed                  =   12345\n",
    "X                     =   X_train\n",
    "y                     =   y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other Linear Models\n",
      "\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Ridge regression\n",
      "--------------------------------------\n",
      "RMSE is 10.28425444268223\n",
      "MAPE is 30.73687002900695\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Lasso regression\n",
      "--------------------------------------\n",
      "RMSE is 10.287164739928244\n",
      "MAPE is 30.838741686702022\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Elsasticnet regression\n",
      "--------------------------------------\n",
      "RMSE is 10.28536906864074\n",
      "MAPE is 30.79460310596816\n",
      "\n",
      "Other Non Linear Models\n",
      "\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "CART regression\n",
      "--------------------------------------\n",
      "RMSE is 0.5748490917895828\n",
      "MAPE is 0.15747031194231098\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Random forest regression\n",
      "--------------------------------------\n",
      "RMSE is 2.210776925933515\n",
      "MAPE is 5.095857583457737\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Gradient Boosting regression\n",
      "--------------------------------------\n",
      "RMSE is 3.6502454977381755\n",
      "MAPE is 9.385840937349945\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "SVR regression\n",
      "--------------------------------------\n",
      "RMSE is 10.549461821704725\n",
      "MAPE is 29.760413943787746\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "KNN regression\n",
      "--------------------------------------\n",
      "RMSE is 7.161412984317847\n",
      "MAPE is 20.75739949885169\n",
      "\n",
      "\n",
      "The model performance for training set - \n",
      "Neural Network regression\n",
      "--------------------------------------\n",
      "RMSE is 16.221082153672523\n",
      "MAPE is 56.17067026350943\n"
     ]
    }
   ],
   "source": [
    "print('\\nOther Linear Models\\n')\n",
    "\n",
    "\n",
    "\n",
    "report_rmse_mape(lm_elastic, y, X, 'The model performance for training set - \\nElsasticnet regression')\n",
    "\n",
    "print('\\nOther Non Linear Models\\n')\n",
    "\n",
    "report_rmse_mape(lm_CART, y, X, 'The model performance for training set - \\nCART regression')\n",
    "report_rmse_mape(lm_RF, y, X,   'The model performance for training set - \\nRandom forest regression')\n",
    "report_rmse_mape(lm_GB, y, X,   'The model performance for training set - \\nGradient Boosting regression')\n",
    "report_rmse_mape(lm_SVR, y, X,  'The model performance for training set - \\nSVR regression')\n",
    "report_rmse_mape(lm_KNN, y, X,  'The model performance for training set - \\nKNN regression')\n",
    "report_rmse_mape(lm_ANN, y, X,  'The model performance for training set - \\nNeural Network regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### For testing dataset\n",
    "seed                  =   12345\n",
    "X                     =   X_test\n",
    "y                     =   y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other Linear Models\n",
      "\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Ridge regression\n",
      "--------------------------------------\n",
      "RMSE is 10.630824528151651\n",
      "MAPE is 32.800547581387825\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Lasso regression\n",
      "--------------------------------------\n",
      "RMSE is 10.63250210808717\n",
      "MAPE is 32.901672169697\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Elsasticnet regression\n",
      "--------------------------------------\n",
      "RMSE is 10.631645631613996\n",
      "MAPE is 32.86193566967066\n",
      "\n",
      "Other Non Linear Models\n",
      "\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "CART regression\n",
      "--------------------------------------\n",
      "RMSE is 6.056301149753441\n",
      "MAPE is 14.563738165213444\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Random forest regression\n",
      "--------------------------------------\n",
      "RMSE is 6.150536680671961\n",
      "MAPE is 14.790039862335297\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Gradient Boosting regression\n",
      "--------------------------------------\n",
      "RMSE is 5.685615822808401\n",
      "MAPE is 14.35568453834877\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "SVR regression\n",
      "--------------------------------------\n",
      "RMSE is 11.04773122975129\n",
      "MAPE is 31.98790281471063\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "KNN regression\n",
      "--------------------------------------\n",
      "RMSE is 8.641986776019342\n",
      "MAPE is 26.253752745821707\n",
      "\n",
      "\n",
      "The model performance for testing set - \n",
      "Neural Network regression\n",
      "--------------------------------------\n",
      "RMSE is 17.008056325246685\n",
      "MAPE is 64.53944050255772\n"
     ]
    }
   ],
   "source": [
    "print('\\nOther Linear Models\\n')\n",
    "\n",
    "\n",
    "\n",
    "report_rmse_mape(lm_elastic, y, X, 'The model performance for testing set - \\nElsasticnet regression')\n",
    "\n",
    "print('\\nOther Non Linear Models\\n')\n",
    "\n",
    "report_rmse_mape(lm_CART, y, X, 'The model performance for testing set - \\nCART regression')\n",
    "report_rmse_mape(lm_RF, y, X,   'The model performance for testing set - \\nRandom forest regression')\n",
    "report_rmse_mape(lm_GB, y, X,   'The model performance for testing set - \\nGradient Boosting regression')\n",
    "report_rmse_mape(lm_SVR, y, X,  'The model performance for testing set - \\nSVR regression')\n",
    "report_rmse_mape(lm_KNN, y, X,  'The model performance for testing set - \\nKNN regression')\n",
    "report_rmse_mape(lm_ANN, y, X,  'The model performance for testing set - \\nNeural Network regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
