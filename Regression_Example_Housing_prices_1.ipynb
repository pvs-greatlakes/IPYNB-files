{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston Housing Data\n",
    "# Description: Predict the house price in Boston from house details\n",
    "# Type: Regression\n",
    "# Dimensions: 506 instances, 14 attributes\n",
    "# Inputs: Numeric\n",
    "# Output: Numeric\n",
    "# UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use advertising data to build a model to predict sales based on  predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas                       as     pd\n",
    "import numpy                        as     np\n",
    "import scipy.stats                  as     stats\n",
    "\n",
    "import seaborn                      as     sns\n",
    "import matplotlib.pyplot            as     plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "import astropy.table                as     Table\n",
    "import statsmodels.api              as     sm\n",
    "import statsmodels.stats.api        as     sms\n",
    "from   statsmodels.compat           import lzip\n",
    "import statsmodels.formula.api      as     smf\n",
    "\n",
    "from   sklearn.cross_validation     import train_test_split\n",
    "from   sklearn                      import model_selection\n",
    "\n",
    "from   sklearn.linear_model         import LinearRegression\n",
    "from   sklearn.linear_model         import Ridge\n",
    "from   sklearn.linear_model         import Lasso\n",
    "from   sklearn.tree                 import DecisionTreeRegressor\n",
    "\n",
    "from   sklearn.neighbors            import KNeighborsRegressor\n",
    "from   sklearn.svm                  import SVR\n",
    "\n",
    "from   sklearn.model_selection      import GridSearchCV\n",
    "from   sklearn.model_selection      import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from   sklearn.metrics              import mean_squared_error, mean_absolute_error\n",
    "from   statsmodels.compat           import lzip\n",
    "from   statsmodels.stats            import diagnostic as diag\n",
    "\n",
    "from  statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "                 0          1          2          3          4\n",
      "CRIM       0.00632    0.02731    0.02729    0.03237    0.06905\n",
      "ZN        18.00000    0.00000    0.00000    0.00000    0.00000\n",
      "INDUS      2.31000    7.07000    7.07000    2.18000    2.18000\n",
      "CHAS       0.00000    0.00000    0.00000    0.00000    0.00000\n",
      "NOX        0.53800    0.46900    0.46900    0.45800    0.45800\n",
      "RM         6.57500    6.42100    7.18500    6.99800    7.14700\n",
      "AGE       65.20000   78.90000   61.10000   45.80000   54.20000\n",
      "DIS        4.09000    4.96710    4.96710    6.06220    6.06220\n",
      "RAD        1.00000    2.00000    2.00000    3.00000    3.00000\n",
      "TAX      296.00000  242.00000  242.00000  222.00000  222.00000\n",
      "PTRATIO   15.30000   17.80000   17.80000   18.70000   18.70000\n",
      "B        396.90000  396.90000  392.83000  394.63000  396.90000\n",
      "LSTAT      4.98000    9.14000    4.03000    2.94000    5.33000\n",
      "Price     24.00000   21.60000   34.70000   33.40000   36.20000\n"
     ]
    }
   ],
   "source": [
    "housing_prices_df       =    pd.read_csv('D:\\RRD\\Courseware\\data/boston_house_prices.csv', header = 0)\n",
    "print(housing_prices_df.shape)\n",
    "print(housing_prices_df.head().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null int64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null int64\n",
      "TAX        506 non-null int64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "Price      506 non-null float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.4 KB\n"
     ]
    }
   ],
   "source": [
    "housing_prices_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "Price      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prices_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prices_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and remove variables of near zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM          73.904671\n",
       "ZN           543.936814\n",
       "INDUS         47.064442\n",
       "CHAS           0.064513\n",
       "NOX            0.013428\n",
       "RM             0.493671\n",
       "AGE          792.358399\n",
       "DIS            4.434015\n",
       "RAD           75.816366\n",
       "TAX        28404.759488\n",
       "PTRATIO        4.686989\n",
       "B           8334.752263\n",
       "LSTAT         50.994760\n",
       "Price         84.586724\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prices_df.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prices_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set into dependent and independent variables, X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X          =   housing_prices_df[['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']]\n",
    "y          =   housing_prices_df['Price']\n",
    "print(X.shape)                            \n",
    "print(y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model         = smf.ols( 'Price ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX  + PTRATIO + B + LSTAT', \\\n",
    "                        data = housing_prices_df)\n",
    "results       = model.fit() ## OLS(output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 01 Jun 2019</td> <th>  Prob (F-statistic):</th> <td>6.95e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:36:00</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4911</td> <td>    5.104</td> <td>    7.149</td> <td> 0.000</td> <td>   26.462</td> <td>   46.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>      <td>   -0.1072</td> <td>    0.033</td> <td>   -3.276</td> <td> 0.001</td> <td>   -0.171</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.380</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>     <td>    0.0209</td> <td>    0.061</td> <td>    0.339</td> <td> 0.735</td> <td>   -0.100</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>    2.6886</td> <td>    0.862</td> <td>    3.120</td> <td> 0.002</td> <td>    0.996</td> <td>    4.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>       <td>  -17.7958</td> <td>    3.821</td> <td>   -4.658</td> <td> 0.000</td> <td>  -25.302</td> <td>  -10.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>    3.8048</td> <td>    0.418</td> <td>    9.102</td> <td> 0.000</td> <td>    2.983</td> <td>    4.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>       <td>    0.0008</td> <td>    0.013</td> <td>    0.057</td> <td> 0.955</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>   -1.4758</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.868</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>       <td>    0.3057</td> <td>    0.066</td> <td>    4.608</td> <td> 0.000</td> <td>    0.175</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.278</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>   <td>   -0.9535</td> <td>    0.131</td> <td>   -7.287</td> <td> 0.000</td> <td>   -1.211</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>         <td>    0.0094</td> <td>    0.003</td> <td>    3.500</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>   -0.5255</td> <td>    0.051</td> <td>  -10.366</td> <td> 0.000</td> <td>   -0.625</td> <td>   -0.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.029</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 782.015</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>1.54e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.276</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Sat, 01 Jun 2019   Prob (F-statistic):          6.95e-135\n",
       "Time:                        08:36:00   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4911      5.104      7.149      0.000      26.462      46.520\n",
       "CRIM          -0.1072      0.033     -3.276      0.001      -0.171      -0.043\n",
       "ZN             0.0464      0.014      3.380      0.001       0.019       0.073\n",
       "INDUS          0.0209      0.061      0.339      0.735      -0.100       0.142\n",
       "CHAS           2.6886      0.862      3.120      0.002       0.996       4.381\n",
       "NOX          -17.7958      3.821     -4.658      0.000     -25.302     -10.289\n",
       "RM             3.8048      0.418      9.102      0.000       2.983       4.626\n",
       "AGE            0.0008      0.013      0.057      0.955      -0.025       0.027\n",
       "DIS           -1.4758      0.199     -7.398      0.000      -1.868      -1.084\n",
       "RAD            0.3057      0.066      4.608      0.000       0.175       0.436\n",
       "TAX           -0.0123      0.004     -3.278      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9535      0.131     -7.287      0.000      -1.211      -0.696\n",
       "B              0.0094      0.003      3.500      0.001       0.004       0.015\n",
       "LSTAT         -0.5255      0.051    -10.366      0.000      -0.625      -0.426\n",
       "==============================================================================\n",
       "Omnibus:                      178.029   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              782.015\n",
       "Skew:                           1.521   Prob(JB):                    1.54e-170\n",
       "Kurtosis:                       8.276   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model using statsmodel using the entire data to check assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_            = sm.add_constant(X)\n",
    "model         = sm.OLS(y, X).fit()\n",
    "predictions   = model.predict(X)\n",
    "\n",
    "## Print the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) No outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we try to get the studentized residuals using get_influence( ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAElCAYAAADjk4nIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b6a380b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.boxplot(rot = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OLS' object has no attribute 'get_influence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ced30f3d6c8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minfluence\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_influence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresid_student\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfluence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresid_studentized_external\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OLS' object has no attribute 'get_influence'"
     ]
    }
   ],
   "source": [
    "influence     = model.get_influence()  \n",
    "resid_student = influence.resid_studentized_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all(x > 3 for x in resid_student) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resid = pd.concat([X, pd.Series(resid_student,name = \"Studentized Residuals\")],axis = 1)\n",
    "resid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the absolute value of studentized residuals is more than 3 then that observation is considered as an outlier and hence should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X[np.absolute(resid['Studentized Residuals'] > 3)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) No multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2018/01/linear-regression-in-python.html\n",
    "\n",
    "Multi-collinearity increases the estimate of standard error of regression coefficients which makes some variables statistically insignificant when they should be significant.\n",
    "\n",
    "We can detect multi-collinearity by:\n",
    "+ By plotting scatter plots between predictor variables to have a visual description of their relationship.\n",
    "+ By calculating the correlation coefficients between the variables we learn the extent of multi-collinearity in the data.\n",
    "+ By calculating the Variable Inflation Factor (VIF) for each variable. \n",
    "VIF measures how much the variance of an estimated regression coefficients increases if your predictors are correlated.  The higher the value of VIF for the regressor, the more it is highly correlated to other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF for a predictor variable is given by $\\frac{1}{1 - R^2}$.\n",
    "Here we take one of the explanatory variables as the target variable and all others as independent variables. So we run a regression between one of those independent variables with remaining independent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Detecting and Removing Multicollinearity \n",
    "\n",
    "##### We use the statsmodels library to calculate VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_vif(x):\n",
    "    thresh = 5.0\n",
    "    output = pd.DataFrame()\n",
    "    k = x.shape[1]\n",
    "    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n",
    "    for i in range(1,k):\n",
    "        print(\"Iteration no.\")\n",
    "        print(i)\n",
    "        print(vif)\n",
    "        a = np.argmax(vif)\n",
    "        print(\"Max VIF is for variable no.:\")\n",
    "        print(a)\n",
    "        if vif[a] <= thresh :\n",
    "            break\n",
    "        if i == 1 :          \n",
    "            output = x.drop(x.columns[a], axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "        elif i > 1 :\n",
    "            output = output.drop(output.columns[a],axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pure = calculate_vif(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pure.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pure.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is no multi-collinearity as their value is below 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Constant variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking heteroscedasticity Using Goldfeld Quandt we test for heteroscedasticity.\n",
    "Null Hypothesis: Error terms are homoscedastic\n",
    "Alternative Hypothesis: Error terms are heteroscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(model.resid, model.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.2993 hence we can say that the residuals have constant variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) No autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for autocorrelation To ensure the absence of autocorrelation we use Ljungbox test.\n",
    "\n",
    "####  Null Hypothesis: Autocorrelation is absent.\n",
    "#### Alternative Hypothesis: Autocorrelation is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diag.acorr_ljungbox(model.resid, lags = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since p-value is 0.8539 thus we can accept the null hypothesis and can say that autocorrelation is absent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Normality of the residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use Jarque-Bera test  from scipy library to check the normality of residuals.\n",
    "\n",
    "#### Null Hypothesis: The residuals are normally distributed.\n",
    "\n",
    "####  Alternative Hypothesis: The residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jb_stat, jb_pval = stats.jarque_bera(model.resid)\n",
    "print('Jarque-Bera test P value is %1.4f' % jb_pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig     = plt.figure()\n",
    "ax1     = fig.add_subplot(211)\n",
    "prob    = stats.probplot(model.resid, dist = stats.norm, plot = ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_title('Probplot against normal distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(model.resid, shade=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The residuals are normally distributed since the p-value (0.0503) is >  0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dataunderthehood.com/2018/01/15/box-cox-transformation-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2018/01/linear-regression-in-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The residual vs fitted values plot is used to check for constant variance and linearity, and to identify potential outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "residuals  =  model.resid\n",
    "# Plot the residuals after fitting a linear model\n",
    "ax         = sns.residplot(y, residuals, lowess = True, color = \"g\")\n",
    "\n",
    "ax.set(xlabel='Fitted Value', ylabel='Residuals', title = 'Residual Vs Fitted values PLOT \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The residual plot indicates that the model’s residuals are restricting to mean of zero to a great extent exhibiting linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split the data into train and test datasets\n",
    "\n",
    "* Use the train data to build a model.\n",
    "* Use the test data to evaluate the model performance.\n",
    "* Slit the data into 80:20 ratio to create train and test data\n",
    "* Set a random seed to ensure repeatability of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test,  y_train, y_test = train_test_split(X_pure, y, test_size = 0.30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_names      = ['x_train shape', 'x_test shape', 'y_train shape', 'y_test shape']\n",
    "shapes        = (x_train.shape, x_test.shape,  y_train.shape, y_test.shape)\n",
    "types         = (type(x_train), type(x_test), type(y_train),type(y_test))\n",
    "lzip(df_names,shapes, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm                  = sm.OLS(y_train, x_train, hasconst = False).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression equation is given by:\n",
    "\n",
    "Sales = 3.86577 + 0.09269 * TV + 0.03462 * Radio + 0.01597 * Newspaper -0.000466 * $TV^2$ + 0.0015105 * TV X Radio - 0.0002586 * TV X Newspaper - 9.39196 * $Radio^2$ - 0.0007483 X Radio X Newspaper + 0.0002933 * $Newspaper^2$  + 0.000000081533 * $TV^3$ - 0.0000016885 * $TV^2$ X Radio - 0.00000100052 * $TV^2$ X Newspaper - 0.0000023998 * $Radio^2$ X TV - 0.00000198309 * $TV$ * $Radio$ * $Newspaper$ - 0.000000332817 * $Newspaper^2$ * TV - 0.00000907886 * $Radio^3$ + 0.0000097386 * $Radio^2$ * Newspaper + 0.0000052069 * $Newspaper^2$ X Radio - 0.000003027 * $Newspaper^3$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We will evaluate our model using RMSE, MAPE and R2-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy\n",
    "\n",
    "Prediction error or residuals is the difference between the predicted target variable values and the actual target variable vaues.\n",
    "\n",
    "Most popular measure to evaluate the model performance is Root Mean Square Error (RMSE) which is the arithmatic mean of the sum of the residuals.\n",
    "\n",
    "The model with low RMSE is the best model among many other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "\n",
    "y_train_predict       = lm.predict(x_train)\n",
    "\n",
    "rmse_train            = np.sqrt(mean_squared_error(y_train, y_train_predict))\n",
    "mape_train            = mean_absolute_percentage_error(y_train, y_train_predict)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse_train))\n",
    "\n",
    "print('MAPE is {}'.format(mape_train))\n",
    "print('R square is %1.3f' % lm.rsquared_adj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "x_test_                  =   sm.add_constant(x_test) \n",
    "y_test_predict           =   lm.predict(x_test)\n",
    "rmse_test                =   (np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "mape_test                =   mean_absolute_percentage_error(y_test, y_test_predict)\n",
    "\n",
    "print('RMSE is {}'.format(rmse_test))\n",
    "print('MAPE is {}'.format(mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if ridge or lasso regression is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ridge regression, we introduce GridSearchCV, which allow us to automatically perform 5-fold cross-validation with a range of different regularization parameters in order to find the optimal value of alpha.\n",
    "Ref: https://towardsdatascience.com/how-to-perform-lasso-and-ridge-regression-in-python-3b3b75541ad8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge    =  Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict      =  {'alpha' : [1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 20, 30]}\n",
    "ridge_regressor =  GridSearchCV(ridge, param_dict, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "ridge_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Ridge(alpha = 30,  fit_intercept = False, random_state = 12345)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the coefficients of the Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_dict_ridge = {}\n",
    "for coef, feat in zip(clf.coef_, x_train.columns):\n",
    "    coef_dict_ridge[feat] = coef\n",
    "print(coef_dict_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_train_rr    = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = clf.predict(x_train))))\n",
    "mape_train_rr    = mean_absolute_percentage_error(y_train,y_pred = clf.predict(x_train))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE    is {}'.format(rmse_train_rr))\n",
    "print('MAPE    is {}'.format(mape_train_rr))\n",
    "print('Rsquare is {}'.format(clf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_test_rr    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = clf.predict(x_test))))\n",
    "mape_test_rr    = mean_absolute_percentage_error(y_test, y_pred = clf.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse_test_rr ))\n",
    "print('MAPE is {}'.format(mape_test_rr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso                      =  Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict       =  {'alpha' : [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 20]}\n",
    "lasso_regressor  =  GridSearchCV(lasso, param_dict, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "lasso_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = Lasso(alpha = 0.01)\n",
    "clf1.fit(x_train, y_train)\n",
    "print('Rsquare is {}'.format(clf1.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the coefficients of the Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_dict_lasso = {}\n",
    "for coef, feat in zip(clf1.coef_, x_train.columns):\n",
    "    coef_dict_lasso[feat] = coef\n",
    "print(coef_dict_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_train_lasso    = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = clf1.predict(x_train))))\n",
    "mape_train_lasso    = mean_absolute_percentage_error(y_train,y_pred = clf1.predict(x_train))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_lasso ))\n",
    "print('MAPE is {}'.format(mape_train_lasso ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_test_lasso    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = clf1.predict(x_test))))\n",
    "mape_test_lasso    = mean_absolute_percentage_error(y_test, y_pred = clf1.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse_test_lasso ))\n",
    "print('MAPE is {}'.format(mape_test_lasso ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees (CART)\n",
    "\n",
    "Decision trees or the Classification and Regression Trees (CART as they are known) use the training data to select the best points to split the data in order to minimize a cost metric. The default cost metric for regression decision trees is the mean squared error, specified in the criterion parameter.\n",
    "\n",
    "You can create a CART model for regression using the DecisionTreeRegressor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, refer https://machinelearningmastery.com/spot-check-regression-machine-learning-algorithms-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X                      =   x_train\n",
    "Y                      =   y_train\n",
    "seed                   =   12345\n",
    "\n",
    "## Create and fit the model\n",
    "\n",
    "kfold                  = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model                  = DecisionTreeRegressor()\n",
    "model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Predict from the model for training data\n",
    "\n",
    "y_pred      =  model.predict(x_train)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df          =  pd.DataFrame({'Actual':y_train, 'Predicted':y_pred})  \n",
    "print(df.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_train_CART    = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))))\n",
    "mape_train_CART    = mean_absolute_percentage_error(y_train,y_pred = model.predict(x_train))\n",
    "score              = model.score(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_CART))\n",
    "print('MAPE is {}'.format(mape_train_CART))\n",
    "print('R Square is {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_dict_CART = {}\n",
    "for coef, feat in zip(model.coef_, x_train.columns):\n",
    "    coef_dict_CART[feat] = coef\n",
    "print(coef_dict_CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Predict from the model for testing data\n",
    "\n",
    "y_pred      =  model.predict(x_test)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df1          =  pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "print(df1.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_test_CART    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))))\n",
    "mape_test_CART    = mean_absolute_percentage_error(y_test, y_pred = model.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for test set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_CART))\n",
    "print('MAPE is {}'.format(mape_test_CART))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-py.html\n",
    "https://theprofessionalspoint.blogspot.com/2019/02/implement-decision-tree-algorithm-in_22.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (or KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (or KNN) locates the K most similar instances in the training dataset for a new data instance. From the K neighbors, a mean or median output variable is taken as the prediction. Of note is the distance metric used (the metric argument). The Minkowski distance is used by default, which is a generalization of both the Euclidean distance (used when all inputs have the same scale) and Manhattan distance (for when the scales of the input variables differ).\n",
    "You can construct a KNN model for regression using the KNeighborsRegressor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed                   =  12345\n",
    "kfold                  =  model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model                  =  KNeighborsRegressor()\n",
    "scoring                =  'neg_mean_squared_error'\n",
    "model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Predict from the model for training data\n",
    "\n",
    "y_pred      =  model.predict(x_train)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df          =  pd.DataFrame({'Actual':y_train, 'Predicted':y_pred})  \n",
    "print(df.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_train_KNN     = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))))\n",
    "mape_train_KNN     = mean_absolute_percentage_error(y_train,y_pred = model.predict(x_train))\n",
    "score              = model.score(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_KNN))\n",
    "print('MAPE is {}'.format(mape_train_KNN))\n",
    "print('R Square is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Predict from the model for testing data\n",
    "\n",
    "y_pred      =  model.predict(x_test)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df1          =  pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "print(df1.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_test_KNN    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))))\n",
    "mape_test_KNN    = mean_absolute_percentage_error(y_test, y_pred = model.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for test set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_KNN ))\n",
    "print('MAPE is {}'.format(mape_test_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) were developed for binary classification. The technique has been extended for the prediction real-valued problems called Support Vector Regression (SVR). Like the classification example, SVR is built upon the LIBSVM library.\n",
    "You can create an SVM model for regression using the SVR class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed                =  12345\n",
    "kfold               =  model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model               =  SVR()\n",
    "scoring             =  'neg_mean_squared_error'\n",
    "\n",
    "model_selection.cross_val_score(model, X, Y, cv = kfold, scoring = scoring)\n",
    "model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Predict from the model for training data\n",
    "\n",
    "y_pred      =  model.predict(x_train)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df          =  pd.DataFrame({'Actual':y_train, 'Predicted':y_pred})  \n",
    "print(df.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_train_SVR     = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))))\n",
    "mape_train_SVR     = mean_absolute_percentage_error(y_train,y_pred = model.predict(x_train))\n",
    "score              = model.score(x_train, y_train)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_SVR ))\n",
    "print('MAPE is {}'.format(mape_train_SVR))\n",
    "print('R Square is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Predict from the model for testing data\n",
    "\n",
    "y_pred      =  model.predict(x_test)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df1          =  pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "print(df1.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_test_SVR    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))))\n",
    "mape_test_SVR    = mean_absolute_percentage_error(y_test, y_pred = model.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for test set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_SVR ))\n",
    "print('MAPE is {}'.format(mape_test_SVR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
