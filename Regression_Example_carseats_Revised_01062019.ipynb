{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use advertising data to build a model to predict sales based on  predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas                       as     pd\n",
    "import numpy                        as     np\n",
    "import scipy.stats                  as     stats\n",
    "\n",
    "import seaborn                      as     sns\n",
    "import matplotlib.pyplot            as     plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "import astropy.table                as     Table\n",
    "import statsmodels.api              as     sm\n",
    "import statsmodels.stats.api        as     sms\n",
    "from   statsmodels.compat           import lzip\n",
    "\n",
    "from   sklearn.cross_validation     import train_test_split\n",
    "from   sklearn                      import model_selection\n",
    "\n",
    "from   sklearn.linear_model         import LinearRegression\n",
    "from   sklearn.linear_model         import Ridge\n",
    "from   sklearn.linear_model         import Lasso\n",
    "from   sklearn.tree                 import DecisionTreeRegressor\n",
    "\n",
    "from   sklearn.neighbors            import KNeighborsRegressor\n",
    "from   sklearn.svm                  import SVR\n",
    "\n",
    "from   sklearn.model_selection      import GridSearchCV\n",
    "from   sklearn.model_selection      import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from   sklearn.metrics              import mean_squared_error, mean_absolute_error\n",
    "from   statsmodels.compat           import lzip\n",
    "from   statsmodels.stats            import diagnostic as diag\n",
    "\n",
    "from  statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 8)\n",
      "                 0       1       2      3       4\n",
      "Sales          9.5   11.22   10.06    7.4    4.15\n",
      "CompPrice    138.0  111.00  113.00  117.0  141.00\n",
      "Income        73.0   48.00   35.00  100.0   64.00\n",
      "Advertising   11.0   16.00   10.00    4.0    3.00\n",
      "Population   276.0  260.00  269.00  466.0  340.00\n",
      "Price        120.0   83.00   80.00   97.0  128.00\n",
      "Age           42.0   65.00   59.00   55.0   38.00\n",
      "Education     17.0   10.00   12.00   14.0   13.00\n"
     ]
    }
   ],
   "source": [
    "carseats_df       = pd.read_csv('D:/RRD/data/Carseats.csv', \\\n",
    "                                usecols = ['CompPrice', 'Income', 'Advertising', 'Population', 'Price',\\\n",
    "                                           'Age', 'Education','Sales'])\n",
    "print(carseats_df.shape)\n",
    "print(carseats_df.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://raw.githubusercontent.com/LearnDataSci/article-resources/master/Housing%20Price%20Index%20Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 8 columns):\n",
      "Sales          400 non-null float64\n",
      "CompPrice      400 non-null int64\n",
      "Income         400 non-null int64\n",
      "Advertising    400 non-null int64\n",
      "Population     400 non-null int64\n",
      "Price          400 non-null int64\n",
      "Age            400 non-null int64\n",
      "Education      400 non-null int64\n",
      "dtypes: float64(1), int64(7)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "carseats_df .info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales          0\n",
       "CompPrice      0\n",
       "Income         0\n",
       "Advertising    0\n",
       "Population     0\n",
       "Price          0\n",
       "Age            0\n",
       "Education      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__            = carseats_df.apply(lambda x: x.replace(to_replace = 0, value = np.NaN))\n",
    "carseats_df_  =  pd.DataFrame(__.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(carseats_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and remove variables of near zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales              7.975626\n",
       "CompPrice        235.147243\n",
       "Income           783.218239\n",
       "Advertising       44.227343\n",
       "Population     21719.813935\n",
       "Price            560.584436\n",
       "Age              262.449618\n",
       "Education          6.867168\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats_df.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sales', 'CompPrice', 'Income', 'Advertising', 'Population', 'Price',\n",
       "       'Age', 'Education'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Education which is having 7.05 as the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set into dependent and independent variables, X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 7)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "X          =   carseats_df[['CompPrice', 'Income', 'Advertising', 'Population', 'Price','Age', 'Education']]\n",
    "y          =   carseats_df['Sales']\n",
    "print(X.shape)                            \n",
    "print(y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model using statsmodel using the entire data to check assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model         = smf.ols('Sales ~ CompPrice + Income + Advertising + Population + Price + Age + Education', data = carseats_df)\n",
    "results       = model.fit() ## OLS(output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   66.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 01 Jun 2019</td> <th>  Prob (F-statistic):</th> <td>1.41e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:03:52</td>     <th>  Log-Likelihood:    </th> <td> -826.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   1669.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   392</td>      <th>  BIC:               </th> <td>   1701.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    7.7077</td> <td>    1.118</td> <td>    6.896</td> <td> 0.000</td> <td>    5.510</td> <td>    9.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CompPrice</th>   <td>    0.0939</td> <td>    0.008</td> <td>   11.980</td> <td> 0.000</td> <td>    0.079</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>      <td>    0.0129</td> <td>    0.003</td> <td>    3.703</td> <td> 0.000</td> <td>    0.006</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Advertising</th> <td>    0.1309</td> <td>    0.015</td> <td>    8.654</td> <td> 0.000</td> <td>    0.101</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Population</th>  <td>   -0.0001</td> <td>    0.001</td> <td>   -0.180</td> <td> 0.857</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price</th>       <td>   -0.0925</td> <td>    0.005</td> <td>  -18.314</td> <td> 0.000</td> <td>   -0.102</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>         <td>   -0.0450</td> <td>    0.006</td> <td>   -7.485</td> <td> 0.000</td> <td>   -0.057</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Education</th>   <td>   -0.0400</td> <td>    0.037</td> <td>   -1.077</td> <td> 0.282</td> <td>   -0.113</td> <td>    0.033</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.263</td> <th>  Durbin-Watson:     </th> <td>   1.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.016</td> <th>  Jarque-Bera (JB):  </th> <td>   7.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.288</td> <th>  Prob(JB):          </th> <td>  0.0212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.639</td> <th>  Cond. No.          </th> <td>4.05e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.05e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.542\n",
       "Model:                            OLS   Adj. R-squared:                  0.533\n",
       "Method:                 Least Squares   F-statistic:                     66.18\n",
       "Date:                Sat, 01 Jun 2019   Prob (F-statistic):           1.41e-62\n",
       "Time:                        08:03:52   Log-Likelihood:                -826.32\n",
       "No. Observations:                 400   AIC:                             1669.\n",
       "Df Residuals:                     392   BIC:                             1701.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       7.7077      1.118      6.896      0.000       5.510       9.905\n",
       "CompPrice       0.0939      0.008     11.980      0.000       0.079       0.109\n",
       "Income          0.0129      0.003      3.703      0.000       0.006       0.020\n",
       "Advertising     0.1309      0.015      8.654      0.000       0.101       0.161\n",
       "Population     -0.0001      0.001     -0.180      0.857      -0.001       0.001\n",
       "Price          -0.0925      0.005    -18.314      0.000      -0.102      -0.083\n",
       "Age            -0.0450      0.006     -7.485      0.000      -0.057      -0.033\n",
       "Education      -0.0400      0.037     -1.077      0.282      -0.113       0.033\n",
       "==============================================================================\n",
       "Omnibus:                        8.263   Durbin-Watson:                   1.969\n",
       "Prob(Omnibus):                  0.016   Jarque-Bera (JB):                7.705\n",
       "Skew:                           0.288   Prob(JB):                       0.0212\n",
       "Kurtosis:                       2.639   Cond. No.                     4.05e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.05e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9 , 3.65, 0.55, ..., 6.  , 2.1 , 0.85],\n",
       "       [5.55, 2.4 , 0.8 , ..., 4.15, 3.25, 0.5 ],\n",
       "       [5.65, 1.75, 0.5 , ..., 4.  , 2.95, 0.6 ],\n",
       "       ...,\n",
       "       [8.1 , 1.3 , 0.6 , ..., 7.95, 2.  , 0.9 ],\n",
       "       [5.  , 3.95, 0.35, ..., 4.75, 2.5 , 0.6 ],\n",
       "       [6.7 , 1.85, 0.  , ..., 6.  , 2.45, 0.8 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(params = 0.05, exog=X) \n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) No outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we try to get the studentized residuals using get_influence( ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.boxplot(rot = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influence     = model.get_influence()  \n",
    "resid_student = influence.resid_studentized_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(x > 3 for x in resid_student) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = pd.concat([X_, pd.Series(resid_student,name = \"Studentized Residuals\")],axis = 1)\n",
    "resid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the absolute value of studentized residuals is more than 3 then that observation is considered as an outlier and hence should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_[np.absolute(resid['Studentized Residuals'] > 3)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) No multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2018/01/linear-regression-in-python.html\n",
    "\n",
    "Multi-collinearity increases the estimate of standard error of regression coefficients which makes some variables statistically insignificant when they should be significant.\n",
    "\n",
    "We can detect multi-collinearity by:\n",
    "+ By plotting scatter plots between predictor variables to have a visual description of their relationship.\n",
    "+ By calculating the correlation coefficients between the variables we learn the extent of multi-collinearity in the data.\n",
    "+ By calculating the Variable Inflation Factor (VIF) for each variable. \n",
    "VIF measures how much the variance of an estimated regression coefficients increases if your predictors are correlated.  The higher the value of VIF for the regressor, the more it is highly correlated to other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF for a predictor variable is given by $\\frac{1}{1 - R^2}$.\n",
    "Here we take one of the explanatory variables as the target variable and all others as independent variables. So we run a regression between one of those independent variables with remaining independent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Detecting and Removing Multicollinearity \n",
    "\n",
    "##### We use the statsmodels library to calculate VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_vif(x):\n",
    "    thresh = 5.0\n",
    "    output = pd.DataFrame()\n",
    "    k = x.shape[1]\n",
    "    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n",
    "    for i in range(1,k):\n",
    "        print(\"Iteration no.\")\n",
    "        print(i)\n",
    "        print(vif)\n",
    "        a = np.argmax(vif)\n",
    "        print(\"Max VIF is for variable no.:\")\n",
    "        print(a)\n",
    "        if vif[a] <= thresh :\n",
    "            break\n",
    "        if i == 1 :          \n",
    "            output = x.drop(x.columns[a], axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "        elif i > 1 :\n",
    "            output = output.drop(output.columns[a],axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure = calculate_vif(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is no multi-collinearity as their value is below 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Constant variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking heteroscedasticity Using Goldfeld Quandt we test for heteroscedasticity.\n",
    "Null Hypothesis: Error terms are homoscedastic\n",
    "Alternative Hypothesis: Error terms are heteroscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(model.resid, model.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.2993 hence we can say that the residuals have constant variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) No autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for autocorrelation To ensure the absence of autocorrelation we use Ljungbox test.\n",
    "\n",
    "####  Null Hypothesis: Autocorrelation is absent.\n",
    "#### Alternative Hypothesis: Autocorrelation is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag.acorr_ljungbox(model.resid, lags = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since p-value is 0.8539 thus we can accept the null hypothesis and can say that autocorrelation is absent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Normality of the residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use Jarque-Bera test  from scipy library to check the normality of residuals.\n",
    "\n",
    "#### Null Hypothesis: The residuals are normally distributed.\n",
    "\n",
    "####  Alternative Hypothesis: The residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_stat, jb_pval = stats.jarque_bera(model.resid)\n",
    "print('Jarque-Bera test P value is %1.4f' % jb_pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig     = plt.figure()\n",
    "ax1     = fig.add_subplot(211)\n",
    "prob    = stats.probplot(model.resid, dist = stats.norm, plot = ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_title('Probplot against normal distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(model.resid, shade=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The residuals are normally distributed since the p-value (0.0503) is >  0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dataunderthehood.com/2018/01/15/box-cox-transformation-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2018/01/linear-regression-in-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The residual vs fitted values plot is used to check for constant variance and linearity, and to identify potential outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals  =  model.resid\n",
    "# Plot the residuals after fitting a linear model\n",
    "ax         = sns.residplot(y, residuals, lowess = True, color = \"g\")\n",
    "\n",
    "ax.set(xlabel='Fitted Value', ylabel='Residuals', title = 'Residual Vs Fitted values PLOT \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The residual plot indicates that the model’s residuals are restricting to mean of zero to a great extent exhibiting linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split the data into train and test datasets\n",
    "\n",
    "* Use the train data to build a model.\n",
    "* Use the test data to evaluate the model performance.\n",
    "* Slit the data into 80:20 ratio to create train and test data\n",
    "* Set a random seed to ensure repeatability of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test,  y_train, y_test = train_test_split(X_pure, y, test_size = 0.30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names      = ['x_train shape', 'x_test shape', 'y_train shape', 'y_test shape']\n",
    "shapes        = (x_train.shape, x_test.shape,  y_train.shape, y_test.shape)\n",
    "types         = (type(x_train), type(x_test), type(y_train),type(y_test))\n",
    "lzip(df_names,shapes, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_            = sm.add_constant(x_train)\n",
    "lm                  = sm.OLS(y_train, x_train_, hasconst = False).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression equation is given by:\n",
    "\n",
    "Sales = 3.86577 + 0.09269 * TV + 0.03462 * Radio + 0.01597 * Newspaper -0.000466 * $TV^2$ + 0.0015105 * TV X Radio - 0.0002586 * TV X Newspaper - 9.39196 * $Radio^2$ - 0.0007483 X Radio X Newspaper + 0.0002933 * $Newspaper^2$  + 0.000000081533 * $TV^3$ - 0.0000016885 * $TV^2$ X Radio - 0.00000100052 * $TV^2$ X Newspaper - 0.0000023998 * $Radio^2$ X TV - 0.00000198309 * $TV$ * $Radio$ * $Newspaper$ - 0.000000332817 * $Newspaper^2$ * TV - 0.00000907886 * $Radio^3$ + 0.0000097386 * $Radio^2$ * Newspaper + 0.0000052069 * $Newspaper^2$ X Radio - 0.000003027 * $Newspaper^3$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We will evaluate our model using RMSE, MAPE and R2-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy\n",
    "\n",
    "Prediction error or residuals is the difference between the predicted target variable values and the actual target variable vaues.\n",
    "\n",
    "Most popular measure to evaluate the model performance is Root Mean Square Error (RMSE) which is the arithmatic mean of the sum of the residuals.\n",
    "\n",
    "The model with low RMSE is the best model among many other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "\n",
    "y_train_predict       = lm.predict(x_train_)\n",
    "\n",
    "rmse_train            = np.sqrt(mean_squared_error(y_train, y_train_predict))\n",
    "mape_train            = mean_absolute_percentage_error(y_train, y_train_predict)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse_train))\n",
    "\n",
    "print('MAPE is {}'.format(mape_train))\n",
    "print('R square is %1.3f' % lm.rsquared_adj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "x_test_                  =   sm.add_constant(x_test) \n",
    "y_test_predict           =   lm.predict(x_test_)\n",
    "rmse_test                =   (np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "mape_test                =   mean_absolute_percentage_error(y_test, y_test_predict)\n",
    "\n",
    "print('RMSE is {}'.format(rmse_test))\n",
    "print('MAPE is {}'.format(mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if ridge or lasso regression is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ridge regression, we introduce GridSearchCV, which allow us to automatically perform 5-fold cross-validation with a range of different regularization parameters in order to find the optimal value of alpha.\n",
    "Ref: https://towardsdatascience.com/how-to-perform-lasso-and-ridge-regression-in-python-3b3b75541ad8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge    =  Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict      =  {'alpha' : [1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 20, 30]}\n",
    "ridge_regressor =  GridSearchCV(ridge, param_dict, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "ridge_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ridge(alpha = 30,  fit_intercept = False, random_state = 12345)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the coefficients of the Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict_ridge = {}\n",
    "for coef, feat in zip(clf.coef_, x_train.columns):\n",
    "    coef_dict_ridge[feat] = coef\n",
    "print(coef_dict_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_rr    = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = clf.predict(x_train))))\n",
    "mape_train_rr    = mean_absolute_percentage_error(y_train,y_pred = clf.predict(x_train))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE    is {}'.format(rmse_train_rr))\n",
    "print('MAPE    is {}'.format(mape_train_rr))\n",
    "print('Rsquare is {}'.format(clf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_rr    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = clf.predict(x_test))))\n",
    "mape_test_rr    = mean_absolute_percentage_error(y_test, y_pred = clf.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse_test_rr ))\n",
    "print('MAPE is {}'.format(mape_test_rr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso                      =  Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict       =  {'alpha' : [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 20]}\n",
    "lasso_regressor  =  GridSearchCV(lasso, param_dict, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "lasso_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Lasso(alpha = 0.01)\n",
    "clf1.fit(x_train, y_train)\n",
    "print('Rsquare is {}'.format(clf1.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the coefficients of the Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict_lasso = {}\n",
    "for coef, feat in zip(clf1.coef_, x_train.columns):\n",
    "    coef_dict_lasso[feat] = coef\n",
    "print(coef_dict_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_lasso    = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = clf1.predict(x_train))))\n",
    "mape_train_lasso    = mean_absolute_percentage_error(y_train,y_pred = clf1.predict(x_train))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_lasso ))\n",
    "print('MAPE is {}'.format(mape_train_lasso ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_lasso    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = clf1.predict(x_test))))\n",
    "mape_test_lasso    = mean_absolute_percentage_error(y_test, y_pred = clf1.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse_test_lasso ))\n",
    "print('MAPE is {}'.format(mape_test_lasso ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees (CART)\n",
    "\n",
    "Decision trees or the Classification and Regression Trees (CART as they are known) use the training data to select the best points to split the data in order to minimize a cost metric. The default cost metric for regression decision trees is the mean squared error, specified in the criterion parameter.\n",
    "\n",
    "You can create a CART model for regression using the DecisionTreeRegressor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, refer https://machinelearningmastery.com/spot-check-regression-machine-learning-algorithms-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X                      =   x_train\n",
    "Y                      =   y_train\n",
    "seed                   =   12345\n",
    "\n",
    "## Create and fit the model\n",
    "\n",
    "kfold                  = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model                  = DecisionTreeRegressor()\n",
    "model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict from the model for training data\n",
    "\n",
    "y_pred      =  model.predict(x_train)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df          =  pd.DataFrame({'Actual':y_train, 'Predicted':y_pred})  \n",
    "print(df.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_CART    = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))))\n",
    "mape_train_CART    = mean_absolute_percentage_error(y_train,y_pred = model.predict(x_train))\n",
    "score              = model.score(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_CART))\n",
    "print('MAPE is {}'.format(mape_train_CART))\n",
    "print('R Square is {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict_CART = {}\n",
    "for coef, feat in zip(model.coef_, x_train.columns):\n",
    "    coef_dict_CART[feat] = coef\n",
    "print(coef_dict_CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict from the model for testing data\n",
    "\n",
    "y_pred      =  model.predict(x_test)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df1          =  pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "print(df1.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_CART    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))))\n",
    "mape_test_CART    = mean_absolute_percentage_error(y_test, y_pred = model.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for test set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_CART))\n",
    "print('MAPE is {}'.format(mape_test_CART))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-py.html\n",
    "https://theprofessionalspoint.blogspot.com/2019/02/implement-decision-tree-algorithm-in_22.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (or KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (or KNN) locates the K most similar instances in the training dataset for a new data instance. From the K neighbors, a mean or median output variable is taken as the prediction. Of note is the distance metric used (the metric argument). The Minkowski distance is used by default, which is a generalization of both the Euclidean distance (used when all inputs have the same scale) and Manhattan distance (for when the scales of the input variables differ).\n",
    "You can construct a KNN model for regression using the KNeighborsRegressor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed                   =  12345\n",
    "kfold                  =  model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model                  =  KNeighborsRegressor()\n",
    "scoring                =  'neg_mean_squared_error'\n",
    "model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict from the model for training data\n",
    "\n",
    "y_pred      =  model.predict(x_train)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df          =  pd.DataFrame({'Actual':y_train, 'Predicted':y_pred})  \n",
    "print(df.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_KNN     = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))))\n",
    "mape_train_KNN     = mean_absolute_percentage_error(y_train,y_pred = model.predict(x_train))\n",
    "score              = model.score(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_KNN))\n",
    "print('MAPE is {}'.format(mape_train_KNN))\n",
    "print('R Square is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict from the model for testing data\n",
    "\n",
    "y_pred      =  model.predict(x_test)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df1          =  pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "print(df1.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_KNN    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))))\n",
    "mape_test_KNN    = mean_absolute_percentage_error(y_test, y_pred = model.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for test set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_KNN ))\n",
    "print('MAPE is {}'.format(mape_test_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) were developed for binary classification. The technique has been extended for the prediction real-valued problems called Support Vector Regression (SVR). Like the classification example, SVR is built upon the LIBSVM library.\n",
    "You can create an SVM model for regression using the SVR class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed                =  12345\n",
    "kfold               =  model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model               =  SVR()\n",
    "scoring             =  'neg_mean_squared_error'\n",
    "\n",
    "model_selection.cross_val_score(model, X, Y, cv = kfold, scoring = scoring)\n",
    "model.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict from the model for training data\n",
    "\n",
    "y_pred      =  model.predict(x_train)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df          =  pd.DataFrame({'Actual':y_train, 'Predicted':y_pred})  \n",
    "print(df.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_SVR     = (np.sqrt(mean_squared_error(y_true = y_train, y_pred = model.predict(x_train))))\n",
    "mape_train_SVR     = mean_absolute_percentage_error(y_train,y_pred = model.predict(x_train))\n",
    "score              = model.score(x_train, y_train)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_train_SVR ))\n",
    "print('MAPE is {}'.format(mape_train_SVR))\n",
    "print('R Square is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict from the model for testing data\n",
    "\n",
    "y_pred      =  model.predict(x_test)\n",
    "\n",
    "print('Type of y_pred is %s' % type(y_pred))\n",
    "\n",
    "print('\\n Compare the difference between the actual and predicted values.')\n",
    "\n",
    "df1          =  pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "print(df1.head(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_SVR    = (np.sqrt(mean_squared_error(y_true = y_test, y_pred = model.predict(x_test))))\n",
    "mape_test_SVR    = mean_absolute_percentage_error(y_test, y_pred = model.predict(x_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The model performance for test set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_SVR ))\n",
    "print('MAPE is {}'.format(mape_test_SVR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
