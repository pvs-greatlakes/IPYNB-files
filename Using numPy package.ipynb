{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy arrays, arrays manipulation, random numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy**, short for Numerical Python is a cornerstone of numerical computing in Python. \n",
    "It provides the data structures, algorithms, and library glue needed for most scientific applications involving numerical data in Python.\n",
    "\n",
    "NumPy has the capabilities including the following:\n",
    "\n",
    "a) A fast and efficient multi-dimensional array object, *ndarray*\n",
    "\n",
    "b) Functions for performing element-wise computations with arrays or mathematical computations between arrays.\n",
    "\n",
    "c) Tools for reading and writing array-based datasets to disk\n",
    "\n",
    "d) Linear algebra operations, random number generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is a large topic.  Let us focus on the following:\n",
    "\n",
    "* 1) Fast vectorized array operations for data munging and cleaning, subsetting and filtering, transformation, and other computations\n",
    "* 2) Common array algorithms like sorting, unique and set operations\n",
    "* 3) Efficient descriptive statistics and aggregating / summarizing data\n",
    "* 4) Expressing conditional logic as array operations instead of iterative statements( loops) with id-elif-else branches.\n",
    "* 5) Group-wise data manipulation (aggregation, transformation, function application).\n",
    "\n",
    "**NumPy is designed for efficiency on large arrays of data. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To check if numpy arrays are faster than other pure python counterparts.\n",
    "Consider a NumPy array of ten million integers and the equivalent Python list.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "my_array    = np.arange(10000000)\n",
    "my_list     = list(range(10000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us multiply each sequence by 2.45555 hundred times in a loop.\n",
    "Using %time measure the Wall times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numpy Arrays speed\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "print('\\nNumpy Arrays speed')\n",
    "%time for _ in range(100): my_array2 = my_array * 2.45555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other Pure Python list speed\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "print('\\nOther Pure Python list speed')\n",
    "%time for _ in range(100): my_list2 = [ x *  2.45555 for x in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.35678391959799"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "85/3.98 # Numpy arrays are about 21 times faster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that calculation using numpy arrays are around 21 times faster than performing calculations using pure python list methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.random.randn return a sample or samples from standard normal distribution with mean 1 and standard deviation 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate a small 2 by 4 array of random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90664013 -0.11620656 -1.12047217  0.45962719]\n",
      " [ 0.0669131  -0.51101505  1.08006919  1.94691573]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.randn(2,4)\n",
    "print(data) # print the array, data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ndarray is a generic multidimensional container for homogeneous data (all data elements are of the same type).\n",
    "Every array has \n",
    "* a shape, a tuple indicating the size of each dimension.\n",
    "* a dtype, an object indicating the data type of the array\n",
    "\n",
    "The data type or dtype is a special object containing information the ndarray needs to interpret a chunck of memory as a particular type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape) # size of each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(data.dtype) # data type of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally *array, ndarray, numpy array* all refer to the same **ndarray** object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do you create ndarray?**\n",
    "\n",
    "Function, array creates a new NumPy array containing the passed data (sequence like object, including other arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.5, 30. , 30.5, 31.5, 22. , 34.5, 33.5, 35. ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age           =  [29.5, 30.0, 30.5, 31.5, 22.0, 34.5, 33.5, 35.0]\n",
    "age_arr1      =  np.array(age)\n",
    "age_arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested sequences, like a list of equal-length lists will be converted into a multi-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [3, 4, 5, 6, 7]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = [[1,2,3,4,5], [3,4,5,6,7]]\n",
    "arr3    = np.array(data3)\n",
    "arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of arr3\n",
      "(2, 5)\n",
      "\n",
      "Dimension of arr3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('\\nShape of arr3')\n",
    "print(arr3.shape)\n",
    "print('\\nDimension of arr3')\n",
    "print(arr3.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of functions for creating new arrays such as zeros, ones to hold os and 1s respectively with a given length of shape. \n",
    "\n",
    "You can create an empty array without initializing its values to any particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creates an array of 10 zeros\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "creates a 2 X 5 array of zeros\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "creates a two 2 X 3 array of zeros\n",
      "[[[1.04723487e-311 2.81617418e-322]\n",
      "  [0.00000000e+000 0.00000000e+000]\n",
      "  [0.00000000e+000 8.60952352e-072]]\n",
      "\n",
      " [[5.33243585e-091 7.62484380e+169]\n",
      "  [8.27014352e-072 1.80069055e+185]\n",
      "  [6.48224659e+170 4.93432906e+257]]]\n"
     ]
    }
   ],
   "source": [
    "print('creates an array of 10 zeros')\n",
    "print(np.zeros(10)) # creates an array of 10 zeros\n",
    "print('\\ncreates a 2 X 5 array of zeros')\n",
    "print(np.zeros((2,5))) # creates a 2 X 5 array of zeros\n",
    "print('\\ncreates a two 2 X 3 array of zeros')\n",
    "print(np.empty((2,3,2))) # Creates a two 3 X 2 array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function, arange is an array-valued version of the built-in Python range function.\n",
    "np.arange(10)\n",
    "\n",
    "page 103 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Array creation functions\n",
    "\n",
    "| Sl No | Functions | Description |\n",
    "| --- | -------- | ----------------------------------- |\n",
    "| 1 | array | Convert input data containing any one of list, tuple, array, or other sequence type to an ndarray either by explicitly specifying a dtype or inferring a dtype; by default copies the input data |\n",
    "| 2 | asarray | Convert input to ndarray, but do not copy if the input is already an ndarray |\n",
    "| 3 | arange | Same as built-in range, but returns an ndarray instead |\n",
    "| 4 | ones, ones_like | Produce an array of all 1s with the given shape and dtype; ones_like takes another array and produces a ones array of the same shape and dtype |\n",
    "| 5 | zeros, zeros_like |  Produce an array of all 0s with the given shape and dtype; zeros_like takes another array and produces a zeros array of the same shape and dtype |\n",
    "| 6 | empty, empty_like | Create new arrays by allocating new memory, but do not populate with any values like ones or zeros |\n",
    "| 7 | full, full_like | Produce an array of  given shape and dtype; with all values set to the indicated 'fill value' full_like takes another array and produces a filled array of the same shape and dtype |\n",
    "| 8 |  eye, identity | Create a square n X n Identity matrix, 1s on digonal and 0 elsewhere |\n",
    "| 9 | matrix | This returns a matrix from an array-like object, or from a string of data. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to create a 2d Identity matrix with 1s on the diagonal and 0s elsewhere?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identity Matrix of 2 dimension\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import          numpy as   np\n",
    "\n",
    "identity_matrix_2d     =   np.identity(2)\n",
    "print('\\nIdentity Matrix of 2 dimension')\n",
    "print(identity_matrix_2d )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data type of array1 float64\n",
      "\n",
      "Data type of array2 int32\n"
     ]
    }
   ],
   "source": [
    "### Specify data types for the array while creating\n",
    "\n",
    "array1 = np.array([1, 3, 4], dtype = np.float64)\n",
    "array2 = np.array([1, 3, 4], dtype = np.int32)\n",
    "\n",
    "print('\\nData type of array1 %s' % array1.dtype)\n",
    "print('\\nData type of array2 %s' % array2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explicitly convert an array from one data type to another using astype method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "array2\n",
      "[1 3 4]\n",
      "\n",
      "Data type of array 2  =  int32\n",
      "\n",
      "Data type of array2_float  =  float64\n",
      "\n",
      "array2_float\n",
      "[1. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "print('\\narray2')\n",
    "print(array2)\n",
    "print('\\nData type of array 2 ', end = ' =  ')\n",
    "print(array2.dtype)\n",
    "array2_float = array2.astype(np.float64)\n",
    "print('\\nData type of array2_float ', end = ' =  ')\n",
    "print(array2_float.dtype)\n",
    "print('\\narray2_float')\n",
    "print(array2_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorization property of NumPy**\n",
    "\n",
    "Arrays are important enables you to do any arithmetic operations between equal-size arrays without writing any for loops.  It applies the operation element-wise.\n",
    "\n",
    "Arithmetic operations include, multiplication (*), subtraction (-), addition (+) and division (/) and power (${**}$).\n",
    "Arithmetic operations with scalars propogate the scalar argument to each element in the array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data * 100  [[ -90.66401272  -11.62065558 -112.04721661   45.96271914]\n",
      " [   6.69130973  -51.10150468  108.00691873  194.6915728 ]]\n",
      "data + data  [[-1.81328025 -0.23241311 -2.24094433  0.91925438]\n",
      " [ 0.13382619 -1.02203009  2.16013837  3.89383146]]\n",
      "data  - 10  [[-10.90664013 -10.11620656 -11.12047217  -9.54037281]\n",
      " [ -9.9330869  -10.51101505  -8.91993081  -8.05308427]]\n",
      "data / 10  [[-0.09066401 -0.01162066 -0.11204722  0.04596272]\n",
      " [ 0.00669131 -0.0511015   0.10800692  0.19469157]]\n",
      "data * 1.4  [[-1.26929618 -0.16268918 -1.56866103  0.64347807]\n",
      " [ 0.09367834 -0.71542107  1.51209686  2.72568202]]\n",
      "data ** 0.5  [[0.95217652 0.34089083 1.05852358 0.6779581 ]\n",
      " [0.25867566 0.71485316 1.03926377 1.39531922]]\n"
     ]
    }
   ],
   "source": [
    "print('data * 100 ',data * 100) # perform mathematical operation, multiply by 100\n",
    "print('data + data ',data + data) # perform mathematical operation, addition\n",
    "print('data  - 10 ',data  - 10) # perform mathematical operation, subtract 10\n",
    "print('data / 10 ', data / 10) # perform division by 10\n",
    "print('data * 1.4 ', data * 1.4) # perform multiplication with scalar 1.4 for each element\n",
    "print('data ** 0.5 ', np.abs(data) ** 0.5) # perform square root for each element after taking absolute value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic indexing and slicing\n",
    "\n",
    "One dimensional arrays are simple and they act similarly to Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "5\n",
      "[5 6 7]\n",
      "[  0   1   2   3   4 100 100 100   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(20)\n",
    "print(array)\n",
    "print(array[5]) # Sixth element\n",
    "print(array[5:8]) # Sixth element to 8th element\n",
    "array[5:8] = 100\n",
    "print(array) # Value given to a slice is propogated to the entire selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Simple Random Sampling\n",
    "\n",
    "This is the simplest type of sampling. \n",
    "\n",
    "Consider a population of size, n and you want to sample k units from this population. Then a **simple random sample** of size, k has the property that every possible sample of size k being chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 )    From the list of 60 employees, select 10 of them randomly for performing night duties next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "import   numpy as np\n",
    "\n",
    "empids = ['E001','E002','E003','E004','E010','E011','E012','E013','E020','E021','E022',\\\n",
    "                  'E023','E024','E025','E026','E027','E028','E029','E030','E031','E032','E035',\\\n",
    "                  'E040','E041','E042','E044','E045','E046','E050','E051','E061','E070','E081',\\\n",
    "                  'E083','E084','E085','E086','E087','E088','E089','E090','E091','E092','E093',\\\n",
    "                  'E094','E095','E096','E097','E098','E100','E101','E121','E131','E135','E701',\\\n",
    "                  'E794','E795','E866','E897','E998' ]\n",
    "print(len(empids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Employee IDs who are selected for night shift\n",
      "\n",
      "['E051' 'E095' 'E020' 'E040' 'E012' 'E701' 'E089' 'E025' 'E030' 'E070']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234) # to ensure repeatability\n",
    "selected_10_empids = np.random.choice(empids, size = 10, replace = False)\n",
    "print('\\nSelected Employee IDs who are selected for night shift\\n')\n",
    "print(selected_10_empids )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple random sample of size 10 where each possible sample of size 10 has the same chance of being chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Stratified random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified random sampling is a method of sampling that involves the division of a population into relatively homogeneous subsets called strata and then random samples are taken from each stratum.\n",
    "Here, we get estimates within each stratum unlike simple random sampling.\n",
    "\n",
    "Ref: Book Business Analytics - Data Analysis and Decision Making - by Albright and Winston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is an open source Python library that implements a range of machine learning, preprocessing, cross-validation and visualization algorithms using a unified interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My version of sklearn is 0.19.1\n",
      "The latest version of sklean is 0.20.3 Refer: https://scikit-learn.org/stable/tutorial/index.html\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sci\n",
    "print('My version of sklearn is %s' %sci.__version__)\n",
    "print('The latest version of sklean is 0.20.3 Refer: %s' %'https://scikit-learn.org/stable/tutorial/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) Use the iris data set preloaded in sklearn datasets. Split the data into 67%:33% so that we have a proper stratefied random sampling and show the value counts of y and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (150, 4)\n",
      "y.shape (150,)\n",
      "\n",
      "Value counts of y containing 150 observations\n",
      "2.0    50\n",
      "1.0    50\n",
      "0.0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "Value counts of y_test containg 50 observations\n",
      "2.0    17\n",
      "1.0    17\n",
      "0.0    16\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas                  as       pd\n",
    "from   sklearn.model_selection import   train_test_split\n",
    "from   sklearn                 import   datasets\n",
    "\n",
    "iris              =  datasets.load_iris()\n",
    "\n",
    "iris_df           =  pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "### Note  np.c_ is the numpy concatenate function\n",
    "\n",
    "y                 =  iris_df['target']\n",
    "X                 =  iris_df.drop(['target'], axis= 1) \n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('y.shape', y.shape)\n",
    "print('\\nValue counts of y containing %d observations' %y.shape[0])\n",
    "print(y.value_counts())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size   = 0.33,\n",
    "                                                    random_state= 12345,\n",
    "                                                    stratify    = y)\n",
    "\n",
    "print('\\nValue counts of y_test containg %d observations' %y_test.shape[0])\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Systematic random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systematic sampling is a probability sampling method where the elements are chosen from  a target population by selecting a random starting point, k  and selecting other members after k, a fixed sampling interval. Here k = N/n where N is the population size and n is the desired sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3) Assume there are 55000 customers and their list is  arranged in the decreasing order of order volumes. You are asked to select 250 customers. So you divide the population size by sample size = 55000 / 250 = 220. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got the population of customers subdivided into 250 customer samples of size 220.\n",
    "So, the sample size, n= 220.\n",
    "So we need to first choose a random number between 1 and 220 (both inclusive) and add the sample size to get other numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First random number 48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 220\n",
    "np.random.seed(1234) # to ensure repeatability\n",
    "k = np.random.randint(1, n, size = 1) \n",
    "print('First random number %d'%k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 268, 488, 708, 928, 1148, 1368, 1588, 1808, 2028, 2248, 2468, 2688, 2908, 3128, 3348, 3568, 3788, 4008, 4228, 4448, 4668, 4888, 5108, 5328, 5548, 5768, 5988, 6208, 6428, 6648, 6868, 7088, 7308, 7528, 7748, 7968, 8188, 8408, 8628, 8848, 9068, 9288, 9508, 9728, 9948, 10168, 10388, 10608, 10828, 11048, 11268, 11488, 11708, 11928, 12148, 12368, 12588, 12808, 13028, 13248, 13468, 13688, 13908, 14128, 14348, 14568, 14788, 15008, 15228, 15448, 15668, 15888, 16108, 16328, 16548, 16768, 16988, 17208, 17428, 17648, 17868, 18088, 18308, 18528, 18748, 18968, 19188, 19408, 19628, 19848, 20068, 20288, 20508, 20728, 20948, 21168, 21388, 21608, 21828, 22048, 22268, 22488, 22708, 22928, 23148, 23368, 23588, 23808, 24028, 24248, 24468, 24688, 24908, 25128, 25348, 25568, 25788, 26008, 26228, 26448, 26668, 26888, 27108, 27328, 27548, 27768, 27988, 28208, 28428, 28648, 28868, 29088, 29308, 29528, 29748, 29968, 30188, 30408, 30628, 30848, 31068, 31288, 31508, 31728, 31948, 32168, 32388, 32608, 32828, 33048, 33268, 33488, 33708, 33928, 34148, 34368, 34588, 34808, 35028, 35248, 35468, 35688, 35908, 36128, 36348, 36568, 36788, 37008, 37228, 37448, 37668, 37888, 38108, 38328, 38548, 38768, 38988, 39208, 39428, 39648, 39868, 40088, 40308, 40528, 40748, 40968, 41188, 41408, 41628, 41848, 42068, 42288, 42508, 42728, 42948, 43168, 43388, 43608, 43828, 44048, 44268, 44488, 44708, 44928, 45148, 45368, 45588, 45808, 46028, 46248, 46468, 46688, 46908, 47128, 47348, 47568, 47788, 48008, 48228, 48448, 48668, 48888, 49108, 49328, 49548, 49768, 49988, 50208, 50428, 50648, 50868, 51088, 51308, 51528, 51748, 51968, 52188, 52408, 52628, 52848, 53068, 53288, 53508, 53728, 53948, 54168, 54388, 54608, 54828]\n"
     ]
    }
   ],
   "source": [
    "sample_sizes     = map(lambda x: x * 220 + k, range(0,250))\n",
    "random_nos       = list(map(int,sample_sizes))\n",
    "print(random_nos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you choose a number randomly between 1 and 220. Assume that number is 48.\n",
    "So you would choose 48, 268, 488, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice Exercise 1: **\n",
    "\n",
    "Consider a school with 10000 students, and assume a researcher wants to select 100 of them for further study. All their student ids are numbered from 0 to 9999. \n",
    "Choose 100 students randomly without replacement. Use simple random sample method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import   numpy  as  np\n",
    "studentIds = range(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Student IDs who are selected for further research\n",
      "\n",
      "[2374 1784 6301 1600 7920 6868 9082 9227 6816 1492 4900 6502  786 4147\n",
      " 7824 5680 8443 3196  954 4906 1552 3764 1763 3637 8866 8524 6011 2165\n",
      " 9663 3864 5951  104 5513 6858 2295 9806 3765 3981 1816 5141 7316 4441\n",
      " 7667 1757 9268 2694 7722 7455 6739 9751 3377 3484 2202 3512 7392 4882\n",
      " 2272 1353 7871 5044 3999 3562 1440 4114 2514 3748 1916 2987 9188  212\n",
      " 5590 1293 4915 1435 9034  964 9891 8758 2710 1577 6290  818 1954 1111\n",
      " 3199 8535  315 7654 6564 7356 5068 9421 5997 7868 1914 9493 4885 8686\n",
      " 3829 3066]\n"
     ]
    }
   ],
   "source": [
    "selected_10_studentIds = np.random.choice(studentIds, size = 100, replace = False)\n",
    "print('\\nSelected Student IDs who are selected for further research\\n')\n",
    "print(selected_10_studentIds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice Exercise 2: **\n",
    "\n",
    "Load Breast cancer dataset which is available in sklearn.datasets\n",
    "The target variable, class is a binary class having values Malignant and Benign\n",
    "There are 569 observations and 30 attributes.\n",
    "\n",
    "Class distribution is 212 Malignant and 357 benign (37% and 63%). \n",
    "Split this data set into training and test data set and having the same proportion of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas                    as       pd\n",
    "from   sklearn                   import   datasets\n",
    "from   sklearn.model_selection   import   train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "cancer   = datasets.load_breast_cancer() # Get the diabetes dataset from sklearn\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load the dataset as a pandas data frame\n"
     ]
    }
   ],
   "source": [
    "# Load the Diabetes dataset\n",
    "print('\\nLoad the dataset as a pandas data frame')\n",
    "cancer_df     = pd.DataFrame(data = cancer['data'] , columns = cancer['feature_names']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Define the independent variable as X\n",
      "                                   0            1            2           3\n",
      "mean radius                17.990000    20.570000    19.690000   11.420000\n",
      "mean texture               10.380000    17.770000    21.250000   20.380000\n",
      "mean perimeter            122.800000   132.900000   130.000000   77.580000\n",
      "mean area                1001.000000  1326.000000  1203.000000  386.100000\n",
      "mean smoothness             0.118400     0.084740     0.109600    0.142500\n",
      "mean compactness            0.277600     0.078640     0.159900    0.283900\n",
      "mean concavity              0.300100     0.086900     0.197400    0.241400\n",
      "mean concave points         0.147100     0.070170     0.127900    0.105200\n",
      "mean symmetry               0.241900     0.181200     0.206900    0.259700\n",
      "mean fractal dimension      0.078710     0.056670     0.059990    0.097440\n",
      "radius error                1.095000     0.543500     0.745600    0.495600\n",
      "texture error               0.905300     0.733900     0.786900    1.156000\n",
      "perimeter error             8.589000     3.398000     4.585000    3.445000\n",
      "area error                153.400000    74.080000    94.030000   27.230000\n",
      "smoothness error            0.006399     0.005225     0.006150    0.009110\n",
      "compactness error           0.049040     0.013080     0.040060    0.074580\n",
      "concavity error             0.053730     0.018600     0.038320    0.056610\n",
      "concave points error        0.015870     0.013400     0.020580    0.018670\n",
      "symmetry error              0.030030     0.013890     0.022500    0.059630\n",
      "fractal dimension error     0.006193     0.003532     0.004571    0.009208\n",
      "worst radius               25.380000    24.990000    23.570000   14.910000\n",
      "worst texture              17.330000    23.410000    25.530000   26.500000\n",
      "worst perimeter           184.600000   158.800000   152.500000   98.870000\n",
      "worst area               2019.000000  1956.000000  1709.000000  567.700000\n",
      "worst smoothness            0.162200     0.123800     0.144400    0.209800\n",
      "worst compactness           0.665600     0.186600     0.424500    0.866300\n",
      "worst concavity             0.711900     0.241600     0.450400    0.686900\n",
      "worst concave points        0.265400     0.186000     0.243000    0.257500\n",
      "worst symmetry              0.460100     0.275000     0.361300    0.663800\n",
      "worst fractal dimension     0.118900     0.089020     0.087580    0.173000\n"
     ]
    }
   ],
   "source": [
    "print('\\nDefine the independent variable as X')\n",
    "X = cancer_df \n",
    "print(X.head(4).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Define the dependent variable as y\n",
      "1    357\n",
      "0    212\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nDefine the dependent variable as y')\n",
    "y        =  pd.Series(cancer.target)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split X, y in the ratio 80:20 (Taining data set : Test data set) and try to retain the same target class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Exercise 3: \n",
    "\n",
    "ABC company wants to study into the impact of leadership style on employee motivation level and reduction in attrition. \n",
    "\n",
    "ABC has 240 employees in Operations department who could be potentially interviewed. You identified the sample size as 24 employees. \n",
    "\n",
    "** Select 10 employees randomly  for interviewing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (150, 4)\n",
      "y.shape (150,)\n",
      "\n",
      "Value counts of y containing 150 observations\n",
      "2.0    50\n",
      "1.0    50\n",
      "0.0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "Value counts of y_test containg 50 observations\n",
      "2.0    17\n",
      "1.0    17\n",
      "0.0    16\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas                  as       pd\n",
    "from   sklearn.model_selection import   train_test_split\n",
    "from   sklearn                 import   datasets\n",
    "import numpy                   as       np\n",
    "\n",
    "iris              =  datasets.load_iris()\n",
    "\n",
    "iris_df           =  pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "### Note  np.c_ is the numpy concatenate function\n",
    "\n",
    "y                 =  iris_df['target']\n",
    "X                 =  iris_df.drop(['target'], axis= 1) \n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('y.shape', y.shape)\n",
    "print('\\nValue counts of y containing %d observations' %y.shape[0])\n",
    "print(y.value_counts())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size   = 0.33,\n",
    "                                                    random_state= 12345,\n",
    "                                                    stratify    = iris_df['target'])\n",
    "\n",
    "print('\\nValue counts of y_test containg %d observations' %y_test.shape[0])\n",
    "print(y_test.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
